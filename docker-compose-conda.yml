version: "3.8"

services:
  voice-chat-ai-conda:
    build:
      context: .
      dockerfile: Dockerfile.conda
    image: voice-chat-ai:conda
    container_name: voice-chat-ai-conda
    environment:
      # PulseAudio configuration for different platforms
      - PULSE_SERVER=/mnt/wslg/PulseServer  # Default: WSL2 PulseAudio server
      # - PULSE_SERVER=unix:/tmp/pulse/native  # Uncomment for native Ubuntu/Debian with PulseAudio
    env_file:
      - .env
    volumes:
      # Audio volumes for different platforms
      # WSL2 on Windows (Docker Desktop)
      - \\wsl$\Ubuntu\mnt\wslg:/mnt/wslg/  # Default: WSL2 audio mount for Windows CMD
      # - /mnt/wslg/:/mnt/wslg/  # Uncomment for WSL2 Ubuntu (running Docker inside WSL2)
      # Native Linux
      # - ~/.config/pulse/cookie:/root/.config/pulse/cookie:ro  # Uncomment for native Ubuntu/Debian
      # - /run/user/1000/pulse:/tmp/pulse:ro  # Uncomment and adjust UID for native Ubuntu/Debian
      
      # Application volumes
      - ./outputs:/app/outputs
      - ./characters:/app/characters
      - ./elevenlabs_voices.json:/app/elevenlabs_voices.json
      - ./.env:/app/.env:ro
    ports:
      - "8000:8000"
    restart: unless-stopped
    tty: true
    stdin_open: true
    networks:
      - voice-chat-network

  # Optional: Add Ollama service if using local models
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   restart: unless-stopped
  #   networks:
  #     - voice-chat-network

networks:
  voice-chat-network:
    driver: bridge

# volumes:
#   ollama_data: